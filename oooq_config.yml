extra_args: >-
  --ntp-server pool.ntp.org

network_isolation: true
network_isolation_type: 'single-nic-vlans'

# We're using Pacemaker / HA
enable_pacemaker: true

# We're using Docker, the Galera we're going to run also runs in a docker
# container and the playbook makes use of the existing containers to gather
# information
containerized_overcloud: true


# MAKE IT EASY TO BUILD, STEP 1.  don't use ipv6
overcloud_ipv6: false

# MAKE IT EASY TO BUILD, STEP 2.  Don't use undercloud ceilometer / gnocchi,
# these use up a lot of resources and we don't need them for the demo
undercloud_enable_telemetry: false

# MAKE IT EASY TO BUILD, STEP 3.  Don't have Nova try to spin
# up four VMs at once when deploying overcloud, give nova / ironic
# lots more time to wait for things to finish.
# I had these added to oooq in
# https://review.openstack.org/#/c/527718/
undercloud_nova_max_concurrent_builds: 2
undercloud_nova_rpc_response_timeout: 600
undercloud_ironic_rpc_response_timeout: 600


# MAKE IT EASY TO BUILD, STEP 4.  Don't use ceilometer / gnocchi on
# overcloud either.
telemetry_args: >-
   {% if release != 'newton' %}
   -e {{ overcloud_templates_path }}/environments/disable-telemetry.yaml
   {% endif %}

# NETWORK.    We are taking advantage of a part of oooq where it
# generates a file on the undercloud called network-environment.yaml,
# and then includes this template as part of overcloud deploy.   The
# construction of network-environment.yaml.j2 is such that it takes everything
# under the network_environment_args ansible variable and generically
# expands it to JSON (which also works in YAML).   This is the only
# facility I can locate within oooq that allows me to specify *any* heat
# parameter I need without it being hardcoded somewhere in oooq, so this
# is where all the heat config goes.  Hopefully oooq does not change
# the generic-ness of this file.
network_environment_args:
  # first we're repeating what oooq already has in
  # oooq-extras/roles/overcloud-prep-config/defaults/main.yml
  # note that undercloud cidrs are set up in deploy_overclouds.sh
  # to be *separate* for stack1 and stack2.
  ExternalNetCidr: "{{ undercloud_external_network_cidr }}"
  ExternalAllocationPools: >
    [{'start': '{{ undercloud_external_network_cidr|nthhost(4) }}',
    'end': '{{ undercloud_external_network_cidr|nthhost(250) }}'}]
  NeutronExternalNetworkBridge: ""
  ControlPlaneSubnetCidr: "{{ undercloud_network_cidr|ipaddr('prefix') }}"
  ControlPlaneDefaultRoute: "{{ undercloud_network_cidr|nthhost(1) }}"
  EC2MetadataIp: "{{ undercloud_network_cidr|nthhost(1) }}"
  DnsServers: "{{ overcloud_dns_servers }}"

  # TODO: this was hardcoded to 10.0.0.1 which I think meant that stack2
  # overcloud would route through stack1 undercloud network, changing
  # this but needs to be tested
  ExternalInterfaceDefaultRoute: "{{ undercloud_external_network_cidr|nthhost(1) }}"

  # Set up overcloud CIDRs to be shared between both stack1 and stack2
  # overclouds.    With the oooq setup, these networks are handled by the
  # single "external" libvirt network set up on th hypervisor host by oooq. For
  # simplicity, use the same CIDRs and just isolate the two overclouds by
  # allocated IP number, where the rh_net_range_start / rh_net_range_end values
  # are local to stack1/stack2 and fed in by deploy_overclouds.sh.
  #
  # We only need one of these (or some new network) to
  # stretch between overclouds, which is where the new Galera sits.  We're
  # using the tenant net in this demo, but in a real two-datacenter
  # environment there'd be some other totally new network that is stretched;
  # I didn't figure out how to add a whole new network to oooq / heat templates
  # was easier just to use one that was there.

  InternalApiNetCidr: "172.16.12.0/24"
  InternalApiAllocationPools: [{'start': '172.16.12.{{ rh_net_range_start }}', 'end': '172.16.12.{{ rh_net_range_end }}'}]

  StorageNetCidr: "172.16.11.0/24"
  StorageAllocationPools: [{'start': '172.16.11.{{ rh_net_range_start }}', 'end': '172.16.11.{{ rh_net_range_end }}'}]

  StorageMgmtNetCidr: "172.16.10.0/24"
  StorageMgmtAllocationPools: [{'start': '172.16.10.{{ rh_net_range_start }}', 'end': '172.16.10.{{ rh_net_range_end }}'}]

  TenantNetCidr: "172.16.0.0/24"
  TenantAllocationPools: [{'start': '172.16.0.{{ rh_net_range_start }}', 'end': '172.16.0.{{ rh_net_range_end }}'}]

  # When we have two overclouds, we need to SSH around and we will see these
  # names in our command prompts and you are really going to want to see which
  # stack this is, e.g. "stack1-overcloud-controller-0" and not "overcloud-
  # controller-0", in those names.
  HostnameMap:
    overcloud-controller-0: "{{ rh_stack_name }}-overcloud-controller-0"
    overcloud-controller-1: "{{ rh_stack_name }}-overcloud-controller-1"
    overcloud-controller-2: "{{ rh_stack_name }}-overcloud-controller-2"
    overcloud-compute-0: "{{ rh_stack_name }}-overcloud-compute-0"

  # The overclouds are going to share the same Keystone database.  So lets
  # set up for two different regions, e.g. region_stack1 and region_stack2.
  # at the moment it seems like the OSP12 overclouds default to not using
  # keystone endpoints and instead have service IPs hardcoded, but using
  # endpoint discovery w/ regions is cooler.
  KeystoneRegion: "region_{{ rh_stack_name }}"

  # since we are sharing the same keystone, the services on both
  # overclouds need to use the same passwords.  clearly this would have
  # to be integrated into the "make a bunch of passwords" thing :)
  ManilaPassword: "Manila_password"
  NeutronPassword: "Neutron_password"
  GlancePassword: "Glance_password"
  HeatPassword: "Heat_password"
  AdminPassword: "Admin_password"
  IronicPassword: "Ironic_password"
  HeatStackDomainAdminPassword: "HeatStackDomainAdmin_password"
  ZaqarPassword: "Zaqar_password"
  GnocchiPassword: "Gnocchi_password"
  CeilometerPassword: "Ceilometer_password"
  CinderPassword: "Cinder_password"
  NovaPassword: "Nova_password"
  MistralPassword: "Mistral_password"
  AodhPassword: "Aodh_password"
  SwiftPassword: "Swift_password"
  BarbicanPassword: "Barbican_password"
  SaharaPassword: "Sahara_password"

   

# MAKE IT EASY TO BUILD, STEP 5.  This is some feature in oooq that seems to
# just fail.   We also have ensured we don't run the playbook tags
# overcloud-validate or tripleoui-validate, the latter of which seems to be
# new and has never worked at all for me.
validate_ui_simple: false

# other things taken from default oooq configuration

# This enables TLS for the undercloud which will also make haproxy bind to the
# configured public-vip and admin-vip.
undercloud_generate_service_certificate: false

# This enables the deployment of the overcloud with SSL.
ssl_overcloud: false

# If `run_tempest` is `true`, run tempests tests, otherwise do not
# run them.
tempest_config: false
test_ping: true
run_tempest: false
tempest_workers: 4

# Config for custom tripleo-heat-templates, used in overcloud-prep-config
# overcloud_templates_path: /home/stack/tripleo-heat-templates
# overcloud_templates_repo: https://git.openstack.org/openstack/tripleo-heat-templates
# use templates_branch when not testing with an unmerged review
# overcloud_templates_branch: master
# use templates_refspec when testing with an unmerged review
# overcloud_templates_refspec:

# options below direct automatic doc generation by tripleo-collect-logs
artcl_gen_docs: true
artcl_create_docs_payload:
  included_deployment_scripts:
    - undercloud-install
    - overcloud-custom-tht-script
    - overcloud-prep-containers
    - overcloud-prep-flavors
    - overcloud-prep-images
    - overcloud-prep-network
    - overcloud-deploy
    - overcloud-deploy-post
    - overcloud-validate
  included_static_docs:
    - env-setup-virt
  table_of_contents:
    - env-setup-virt
    - undercloud-install
    - overcloud-custom-tht-script
    - overcloud-prep-containers
    - overcloud-prep-flavors
    - overcloud-prep-images
    - overcloud-prep-network
    - overcloud-deploy
    - overcloud-deploy-post
    - overcloud-validate
